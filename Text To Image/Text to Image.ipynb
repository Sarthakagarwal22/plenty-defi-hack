{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IKfZ8u5KRHEH"},"outputs":[],"source":["  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n","  !git clone https://github.com/openai/CLIP\n","  # !pip install taming-transformers\n","  !git clone https://github.com/CompVis/taming-transformers.git\n","  !rm -Rf clipit\n","  !git clone https://github.com/mfrashad/clipit.git\n","  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n","  !pip install kornia==0.6.1\n","  !pip install imageio-ffmpeg   \n","  !pip install einops\n","  !pip install torch-optimizer\n","  !pip install easydict\n","  !pip install braceexpand\n","  !pip install git+https://github.com/pvigier/perlin-numpy\n","\n","  # ClipDraw deps\n","  !pip install svgwrite\n","  !pip install svgpathtools\n","  !pip install cssutils\n","  !pip install numba\n","  !pip install torch-tools\n","  !pip install visdom\n","\n","  !pip install fastapi\n","  !pip install python-multipart>=0.0.5\n","  !pip install pyngrok uvicorn\n","  !pip install requests\n","  !pip install orjson\n","\n","  !pip3 install opencv-contrib-python\n","  \n","  !git clone https://github.com/BachiLi/diffvg\n","  %cd diffvg\n","  # !ls\n","  !git submodule update --init --recursive\n","  !python setup.py install\n","  %cd ..\n","  \n","  !mkdir -p steps\n","  !mkdir -p models\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zr90JKpFnKgE"},"outputs":[],"source":["import sys\n","import IPython\n","import os\n","\n","\n","sys.path.append(\"clipit\")\n","result_msg = \"setup complete\"\n","if not os.path.isfile(\"first_init_complete\"):\n","  # put stuff in here that should only happen once\n","  !wget https://github.com/fannymonori/TF-LapSRN/raw/master/export/LapSRN_x4.pb\n","  !mkdir -p models\n","  os.mknod(\"first_init_complete\")\n","  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYRmkkKRSsT3"},"outputs":[],"source":["import clipit\n","import torch\n","from fastapi import FastAPI\n","from fastapi.middleware.cors import CORSMiddleware\n","from fastapi import FastAPI, File, UploadFile, Form, BackgroundTasks\n","from fastapi.responses import ORJSONResponse\n","from pydantic import BaseModel\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","import cv2\n","import requests\n","import base64\n","\n","app = FastAPI()\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=['*'],\n","    allow_credentials=True,\n","    allow_methods=['*'],\n","    allow_headers=['*'],\n",")\n","\n","@app.get('/')\n","async def root():\n","    return {'hello': 'world'}\n","\n","class GenerateReqBody(BaseModel):\n","  prompts: str = \"Underwater World\"\n","\n","@app.post(\"/generate\", response_class=ORJSONResponse)\n","async def generate(\n","        reqBody: GenerateReqBody\n","    ):\n","    print(reqBody.prompts)\n","    torch.cuda.empty_cache()\n","    clipit.reset_settings()\n","    reqBody.prompts = reqBody.prompts\n","\n","    clipit.add_settings(prompts=reqBody.prompts,\n","                        iterations=110,\n","                        aspect=\"square\",\n","                        quality=\"draft\",\n","                        scale=1.5,\n","                        use_pixeldraw=False,\n","                        use_clipdraw=False,\n","                        make_video=False)\n","    \n","    settings = clipit.apply_settings()\n","    clipit.do_init(settings)\n","    clipit.do_run(settings)\n","\n","    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n","    path = \"LapSRN_x4.pb\"\n","    sr.readModel(path)\n","    sr.setModel(\"lapsrn\", 4)\n","    sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n","    sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n","    img = cv2.imread('output.png')\n","    result = sr.upsample(img)\n","    cv2.imwrite('output_inc.png', result)\n","    \n","    with open(\"output_inc.png\", \"rb\") as img_file:\n","        my_string = base64.b64encode(img_file.read())\n","    return {\"image_string\": my_string}\n","  \n","\n","ngrok_tunnel = ngrok.connect(8000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","print('Doc URL:', ngrok_tunnel.public_url+'/docs')\n","data = {\n","    \"updateObj\": {\n","        \"aiUrl\": ngrok_tunnel.public_url\n","    }\n","}\n","print(data)\n","r = requests.post(\"https://defining-art.herokuapp.com/util/updateMetaData\", json=data)\n","print(r)\n","nest_asyncio.apply()\n","uvicorn.run(app, port=8000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxtKlzs3x6lI"},"outputs":[],"source":["!pip3 install opencv-contrib-python"]},{"cell_type":"code","source":["!ngrok authtoken 23bi7CDQIj6Kn6fDyr6vrIaKbD6_51YQ67xd6CgBaFqUpXYG4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEy9Jj5YYsvy","executionInfo":{"status":"ok","timestamp":1645600323341,"user_tz":-330,"elapsed":3343,"user":{"displayName":"Sarthak Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhK0YHaYRNRI3uqKRyTLG4DpbXUrDAr22V_W3SlVA=s64","userId":"16442007903058625611"}},"outputId":"6052668d-ea29-413d-87b1-374b38f85721"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Text to Image.ipynb","provenance":[],"authorship_tag":"ABX9TyMTI0UJHFttoun+lBJaGya1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}